{
	"version": "1.0.0",
	"title": "Experiment upon killing spark executor process/es on slave hosts",
	"description": "The spark executor process/es should get auto-respawned after being killed.",
	"tags": ["spark"],
	"controls": [{
		"name": "process-related-controls",
		"provider": {
			"type": "python",
			"module": "chaostoolkit_nimble.controllers.process.control"
		}
	}],
	"steady-state-hypothesis": {
		"title": "Job {{yarn_job_name}} is up and running on yarn",
		"probes": [{
			"type": "probe",
			"name": "Check-job-{{yarn_job_name}}-running-on-yarn",
			"tolerance": true,
			"provider": {
				"module": "chaostoolkit_nimble.core.utils.yarn_apps_ha_utils",
				"type": "python",
				"func": "is_job_running_on_yarn",
				"arguments": {
					"job_name": "{{yarn_job_name}}"
				}
			}
		}]
	},
	"method": [{
		"type": "action",
		"name": "Kill-active-spark-executors-for-job-{{spark_job_name}}",
		"provider": {
			"module": "chaostoolkit_nimble.core.utils.spark_apps_ha_utils",
			"type": "python",
			"func": "kill_active_executors",
			"arguments": {
				"job_name": "{{spark_job_name}}",
				"num_of_exec": "{{num_of_exec_to_kill}}"
			}
		}
	}]
}